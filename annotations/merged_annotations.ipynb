{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b119e12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pysam as ps\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14728757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all variants in +/- 25 bp region around exon-intron boundary (as dataframe available)\n",
    "variants = pd.read_pickle('DataFrame_all_variants')\n",
    "variants = variants.sort_values(by=['#CHROM', 'POS'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56a8c3c",
   "metadata": {},
   "source": [
    "### VEP annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50fb0462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data from vep\n",
    "vep = pd.read_table('vep_download.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c11d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some variants (often insertions) not with HGVSg in VEP --> in VCF format for VEP\n",
    "not_in_vep = variants[~variants['HGVSg'].isin(list(vep['#Uploaded_variation']))].copy()\n",
    "not_in_vep.drop_duplicates(subset=['#CHROM', 'POS', 'REF', 'ALT'], inplace=True, ignore_index=True)\n",
    "not_in_vep['ID'] = not_in_vep['HGVSg']\n",
    "not_in_vep[['#CHROM', 'POS', 'ID', 'REF', 'ALT']].to_csv('02_vep/vep_ins.txt', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ed61904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insertion variants\n",
    "vep_ins = pd.read_table('02_vep/vep_ins.txt')\n",
    "vep = vep.append(vep_ins, ignore_index=True)\n",
    "vep[['transcr']] = vep['Feature'].str.split('.', expand=True)[0]\n",
    "vep_ref = vep[vep['transcr'].isin(variants['RefSeq accession'])].copy()\n",
    "vep_ref.drop_duplicates(inplace=True)\n",
    "vep_ref = vep_ref.reset_index(drop=True)\n",
    "vep_ref = vep_ref.replace('-', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63a2c7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one RefSeq not in vep_ref, but in variants (NM_020732) for gene ARID1B\n",
    "# 25 unique variants are missing\n",
    "# --> RefSeq has been replaced by NM_001374820\n",
    "wrong_refseq = set(vep_ref['transcr']) ^ set(variants['RefSeq accession'])\n",
    "wrong_refseq_vars = variants[variants['RefSeq accession']==list(wrong_refseq)[0]]\n",
    "vep_wrong_refseq = vep[(vep['#Uploaded_variation'].isin(list(wrong_refseq_vars['HGVSg'])))&\n",
    "                       (vep['SYMBOL']==wrong_refseq_vars['HUGO_Symbol'].unique()[0])]\n",
    "vep_wrong_refseq = vep_wrong_refseq[vep_wrong_refseq['transcr']=='NM_001374820']\n",
    "# change RefSeq to herein used RefSeq\n",
    "new_refs = vep_wrong_refseq.copy()\n",
    "new_refs['transcr'] = 'NM_020732'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f69b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "vep_ref = vep_ref.append(new_refs, ignore_index=True)\n",
    "vep_ref = vep_ref.rename(columns={'#Uploaded_variation':'HGVSg', 'transcr':'RefSeq accession'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3275fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge VEP annotations to all variants\n",
    "vars_vep = pd.merge(variants, vep_ref[['IMPACT', 'EXON', 'INTRON', 'cDNA_position', 'CDS_position',\n",
    "                                        'Protein_position', 'Amino_acids', 'Codons', 'DISTANCE', 'STRAND', \n",
    "                                        'SIFT', 'PolyPhen', 'HGVS_OFFSET', 'SpliceAI_pred_DP_AG', \n",
    "                                        'SpliceAI_pred_DP_AL', 'SpliceAI_pred_DP_DG', 'SpliceAI_pred_DP_DL', \n",
    "                                        'SpliceAI_pred_DS_AG', 'SpliceAI_pred_DS_AL', 'SpliceAI_pred_DS_DG', \n",
    "                                        'SpliceAI_pred_DS_DL', 'SpliceAI_pred_SYMBOL', 'CADD_PHRED', 'CADD_RAW', \n",
    "                                        'MaxEntScan_alt', 'MaxEntScan_diff', 'MaxEntScan_ref', 'ada_score', \n",
    "                                        'rf_score', 'HGVSg', 'RefSeq accession']], \n",
    "                    how='left', on=['HGVSg', 'RefSeq accession'])\n",
    "vars_vep = vars_vep.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a49a5df",
   "metadata": {},
   "source": [
    "### FLOSSIES annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02cbc1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previously as dataframe\n",
    "floss = pd.read_pickle('DataFrame_flossies')\n",
    "floss.rename(columns={'CHROM':'#CHROM'}, inplace=True)\n",
    "for df in [floss, vars_vep]:\n",
    "    df['POS'] = df['POS'].astype(int)\n",
    "    df[['#CHROM','REF','ALT']] = df[['#CHROM','REF','ALT']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157b2cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_vep_floss = pd.merge(vars_vep, floss[['#CHROM', 'POS', 'REF', 'ALT', 'Splice_Change_Flossies', \n",
    "                                           'European_(n=7325)_Flossies', 'African_(n=2559)_Flossies',\n",
    "                                           'Overall_Frequency_Flossies', 'European (n=3646)', \n",
    "                                           'African (n=1283)']], \n",
    "                          how='left', on=['#CHROM','POS','REF','ALT'])\n",
    "vars_vep_floss = vars_vep_floss.replace('-', np.nan)\n",
    "vars_vep_floss = vars_vep_floss.replace('.', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4104d8c",
   "metadata": {},
   "source": [
    "### Variants of the HBOC consortium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e48a31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel sheet of HBOC variant database\n",
    "hboc = pd.read_excel('hboc_variants.xlsx')\n",
    "hboc['POS'] = hboc['POS'].astype(int)\n",
    "hboc[['#CHROM','REF','ALT']] = hboc[['#CHROM','REF','ALT']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2b5edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find and eliminate duplicates in this database\n",
    "hboc2 = hboc.copy()\n",
    "hboc2 = hboc2.reset_index(drop=False)\n",
    "dupl2 = hboc2.groupby(['#CHROM', 'POS', 'REF', 'ALT'])\n",
    "dupl_cpra2 = [i for i,df in dupl2 if len(df)>1]\n",
    "#dupl2.get_group(dupl_cpra2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e6ef80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_drop = []\n",
    "for i in dupl_cpra2:\n",
    "    df = dupl2.get_group(i)\n",
    "    if not df[df['ART']=='keine Angabe'].empty and len(df[df['ART']=='keine Angabe'])<2:\n",
    "        for_drop.append(df[df['ART']=='keine Angabe'].iloc[0]['index'])\n",
    "hboc2.drop(index=for_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3726fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dupl3 = hboc2.groupby(['#CHROM', 'POS', 'REF', 'ALT'])\n",
    "dupl_cpra3 = [i for i,df in dupl3 if len(df)>1]\n",
    "#len(dupl_cpra3)\n",
    "#dupl3.get_group(dupl_cpra3[37])\n",
    "#set(hboc.loc[30]) ^ set(hboc.loc[634])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "881424e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index 293/294 (gr1) classes 3/2\n",
    "# index 515/516 (gr6) classes 2/3\n",
    "# index 3366/3367 (gr20) classes 2/3\n",
    "\n",
    "# drop those entries:\n",
    "for_drop2 = [176, 348, 466, 468, 492, 623, 4001, 1190, 1240, 1248, 1302, 1329, 1372, 1373, 1371, 1444, 1462, \n",
    "             1465, 1537, 3419, 3276, 801, 818, 851, 1045, 1061, 1120, 1125, 1135, 1651, 2778, 2905, 1936, 2044, \n",
    "             30, 3035]\n",
    "hboc2.drop(index=for_drop2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9615b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hboc2 = hboc2.rename(columns={'ART':'kind_hboc', 'KLASSIFIKATION':'classification_hboc', \n",
    "                              'ERFASSUNG':'aquisition_hboc', 'TASKFORCE_REVIEWED':'taskforce_review_hboc', \n",
    "                              'DATUM_TASKFORCE_REVIEW':'date_taskforce_hboc', \n",
    "                              'BEMERKUNG_TASKFORCE':'note_hboc', 'SONSTIGE_BEMERKUNGEN':'add_note_hboc', \n",
    "                              'SPLICE_PREDICTION_ALAMUT':'splice_pred_alamut_hboc', \n",
    "                              'PREDICTION_UMD_PREDICTOR':'prediction_hboc', 'KOMMENTAR':'comment_hboc', \n",
    "                              'LITERATUR_ERGEBNIS':'literature_hboc', \n",
    "                              'EVIDENZLEVEL_LITERATUR':'evidence_level_lit_hboc', \n",
    "                              'HANDLUNGSEMPFEHLUNG':'recomm_action_hboc', 'ID':'ID_hboc'})\n",
    "hboc2 = hboc2[['#CHROM', 'POS', 'REF','ALT', 'ID_hboc', 'kind_hboc', 'classification_hboc', 'aquisition_hboc', \n",
    "               'taskforce_review_hboc', 'date_taskforce_hboc', 'note_hboc', 'add_note_hboc', \n",
    "               'splice_pred_alamut_hboc', 'prediction_hboc', 'literature_hboc', 'evidence_level_lit_hboc', \n",
    "               'comment_hboc', 'recomm_action_hboc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44fe5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_vep_floss_hboc = pd.merge(vars_vep_floss, hboc2, on=['#CHROM','POS','REF','ALT'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631b9668",
   "metadata": {},
   "source": [
    "### New SpliceAI scores (for variants without SplicaAI score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d40db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previously as dataframe\n",
    "splai = pd.read_pickle('DataFrame_new_SpliceAI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ac7ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change out missing SpliceIA score with newly generated SpliceAI score\n",
    "new_splai = pd.merge(vars_vep_floss_hboc[vars_vep_floss_hboc['SpliceAI_pred_DP_AG'].isnull()].copy(), \n",
    "                     splai[['#CHROM', 'POS', 'REF', 'ALT', 'DS_AG', 'DS_AL', 'DS_DG', 'DS_DL', 'DP_AG', 'DP_AL', \n",
    "                            'DP_DG', 'DP_DL', 'SYMBOL']], on=['#CHROM', 'POS', 'REF', 'ALT'], how='left')\n",
    "new_splai = new_splai.drop(columns=['SpliceAI_pred_DP_AG','SpliceAI_pred_DP_AL','SpliceAI_pred_DP_DG',\n",
    "                                    'SpliceAI_pred_DP_DL','SpliceAI_pred_DS_AG','SpliceAI_pred_DS_AL',\n",
    "                                    'SpliceAI_pred_DS_DG','SpliceAI_pred_DS_DL','SpliceAI_pred_SYMBOL'], )\n",
    "new_splai = new_splai.rename(columns={i:'SpliceAI_pred_'+i for i in ['DS_AG','DS_AL','DS_DG','DS_DL','DP_AG',\n",
    "                                                                     'DP_AL','DP_DG','DP_DL','SYMBOL']})\n",
    "with_splai = vars_vep_floss_hboc[vars_vep_floss_hboc['SpliceAI_pred_DP_AG'].notnull()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee8ddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_vep_floss_hboc_splai = with_splai.append(new_splai)\n",
    "vars_vep_floss_hboc_splai['#CHROM'] = pd.Categorical(vars_vep_floss_hboc_splai['#CHROM'],\n",
    "                                      categories=['1','2','3','4','5','6','7','8','9','10','11','12', '13', '14', \n",
    "                                                  '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y'],\n",
    "                                      ordered=True)\n",
    "vars_vep_floss_hboc_splai.sort_values(by=['#CHROM', 'POS', 'REF', 'ALT'], inplace=True, ignore_index=True, \n",
    "                       ascending=True)\n",
    "\n",
    "# save variants with all merged annotations together in one dataframe\n",
    "vars_vep_floss_hboc_splai.to_pickle('all_annotated_variants')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
